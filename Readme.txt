<학습에 사용한 이미지의 출처>
이미지넷이라는 외국사이트에 가면 대용량이미지 파일을 다운받을수있다.
강우철교수님 연구실 가장 문쪽에 가까운 PC의 다운로드폴더에 가보면 130GB짜리 알집 파일이 하나있는데 그거사용하면된다.
왠 용량큰 알집파일이있다고 지워버리면 여러분만 피곤해질것이다;;
외국서버에서 받아오는거라 거의 3일동안 받아야하기때문이다.
아무튼 그 폴더를 열어서 자신이 필요하다고 생각되는 이미지들 폴더만 추려서 사용하면된다.

<학습 방법>
Nvidia사의 DIGITS이라는 프레임워크를 사용하였으며 이것에 대한 사용법은 Nvidia홈페이지와 유투브에 가면 잘나와있으니 그것보고 따라하면된다.
내가 설명하는것보다 훨씬 나을것이다.


<간략한 설명>

-soundtext.txt, mylib.cpp, thread.py- : TX1 보드에서 실행
-crop.py- : 라즈베리파이에서 실행

soundtext.txt : TX1보드내에는 미리 녹음해둔 음성파일들이 저장되어있다.(전방에~,~가,~있습니다 등)
또한 미리 학습해둔 클래스의 넘버로 TX1은 전방의 물체를 구별한다.
이 클래스 넘버를 음성파일에 매칭시켜야 하는데 이정보가 soundText.txt에 들어있다.
이 텍스트파일은 mylib.cpp에서 사용할것이다.

mylib.cpp : thread.py로부터 클래스 넘버가 넘어왔을시 그 클래스 넘버가 어떤 물체인지 음성으로 알려주는 역할을 하는 코드이다.
파이선으로 작성해도 되지만 필자가 c/c++가 익숙하기때문에 c/c++로 작성 후 파이선 모듈로 바꾸는 삽질을 하였다.
나중에 누가 이걸 읽을지 모르겠지만 제발 이 코드좀 파이선으로 바꿔달라.
몰라서 못한거아니다 귀찮아서 못한거다

thread.py : 이 캡스턴디자인의 가장 메인이 되는 코드이며 통신으로 받은 이미지를 Classification하는 역할을 한다.
mylib.cpp는 이 코드안에서 사용된다.
이 코드에는 2개의 스레드가 동작하는데 하나의 스레드는 이미지를 받는 스레드, 나머지 하나는 이미지를 식별하는 스레드이다.
4년간 코딩을 제대로 공부한 사람이라면 이 코드의 흐름정도는 파악이 가능할거라 생각한다.

필자는 처음에 스레드를 분리하는것이 효율적이라 생각했는데 곰곰히 생각해보니 굳이 나눌 필요는없어보인다. 왜냐면 음성안내가 3~4초 걸리고 
이 시간내에만 이미지를 받아오면 되므로 이미지를 엄청빠른시간간격으로 받아올 필요가없기때문이다.
이 역시 나중에 누가 이걸 읽을지 모르겠지만 2개 합쳐서 써달라. 굳이 안합쳐도 사용하는덴 지장없다.

crop.py : 이미지를 캡처하고 필요한 부분을 잘라서 그것을 TX1보드로 보내는 역할을한다.
이코드는 라즈베리파이에서 작동한다.

blue.zip : 갤럭시 기어에 올라갔던 타이젠 코드
이 코드는 필자가 작성한 내용이 아니고 이 코드를 작성했던 친구가 휴학을 하는바람에 정확히 설명이 불가능하다.

sound.tar.gz : 2016캡스턴에 사용하였던 음성파일이다.
soundtext.txt에서 사용하는 음성파일이 여기있다.

<사용방법>
1. thread.py와 soundtext.txt, mylib.cpp 모두 같은 폴더에 넣어놓는다.(안해도 되지만 경로를 따로 지정해줘야하기때문에 이렇게하는게 편하다.)
학습모델의 경로는 아무렇게나 해도 무방하다 어차피 코드를 실행할때 인자로 경로를 넣어줘야하기때문이다.

2. 터미널에서 export PYTHONPATH=/home/ubuntu/caffe/python 를 작성후 엔터를 쳐서 파이선패스에 카페파이선경로를 넣어준다.
이것은 임베디드TX1보드를 매번 부팅시 해줘야하며 귀찮다면 .profile등에 작성하여 처리할수도있다.

3. 위 3개의 파일이 있는 폴더에서 python thread.py [model경로]/[모델명]를 실행시킨다.
배치사이즈 등의 수정을 가하기위해선 코드를 살펴보면 인자를 어떻게 넘겨줘야하는지 나온다.
(ex. python thread.py ../model/20160621-231234-a9b0_epoch_86.0.tar)

4. TCP/IP 폴더에 들어있는 crop.py를 실행시킨다.
실행시키면 파이에있는 카메라가 사진을 찍어 TX1보드로 전송하게 되고 TX1보드는 이미지 식별을 통하여 음성안내 및 햅틱기능을 제공하게 된다.
음성안내의 경우 블루투스 이어폰 및 스피커를 사용하면된다.

※햅틱기능을 사용하기 위해서는 블루투스기능이 있는 웨어러블 디바이스가 필요하다.
2016년 캡스턴디자인의 경우 갤럭시기어S2를 사용하였다.
만일 기어가 없는 상황에서 이 코드를 사용하고자 한다면 thread.py에 블루투스 관련된 모든 코드를 주석처리 및 삭제해서 사용하면된다.

또한 당연한 말이지만 반드시 TX1안에서 블루투스를 활성화 시켜놓아야한다.
활성화 안시켜놓으면 기어도 연결안될뿐더러 블루투스이어폰도 연결안되서 식별만되고 음성안내 및 햅틱기능이 나오지않게된다.

<기어사용시 타이젠코드 blue.zip>
이 부분을 담당했던 학생이 중간에 개인사정으로 휴학은하는 바람에 본인은 정확히 어떤 내용인지는 잘 모른다.
개발환경 설정 및 등은 지금 당장 내가 설명해줄수가없다.
코드 자체는 그렇게 어렵진 않지만 아마 개발환경을 구축하는데 조금 어려웠다고 들은것같다.
이 부분은 이 글을 읽는 후배분들이 알아서 해결하셔야할듯합니다..
코드는 있지만 환경을 구축하시는데 시간이 좀 걸릴수도있을겁니다. 의외로 아닐수도있고?




정말 보잘것없고 아직은 불안정한 코드지만 딥러닝을 이용하여 이미지 식별을 하고자할때 조금이라도 도움이 되길바랍니다.
이글을 읽는 4학년 임베디드시스템공학과 후배분들 취업 모두 잘되길바랍니다!

2016-11-11
